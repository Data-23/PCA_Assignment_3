{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be38ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ### Q1. What are Eigenvalues and Eigenvectors? How are they related to the Eigen-Decomposition approach? Explain with an example.\n",
    "\n",
    "# **Answer:**\n",
    "# Eigenvalues and eigenvectors are fundamental concepts in linear algebra. For a square matrix \\(A\\), an eigenvector \\(v\\) is a non-zero vector that changes by a scalar factor when \\(A\\) is applied to it. The scalar factor is known as the eigenvalue \\(\\lambda\\). Mathematically, this is expressed as:\n",
    "# \\[ A v = \\lambda v \\]\n",
    "\n",
    "# **Eigen-Decomposition:** \n",
    "# Eigen-decomposition is a matrix factorization technique where a matrix \\(A\\) is decomposed into the product of its eigenvectors and eigenvalues:\n",
    "# \\[ A = V \\Lambda V^{-1} \\]\n",
    "# where \\(V\\) is a matrix whose columns are the eigenvectors of \\(A\\), and \\(\\Lambda\\) is a diagonal matrix whose diagonal elements are the eigenvalues of \\(A\\).\n",
    "\n",
    "# **Example:**\n",
    "# Consider matrix \\(A\\):\n",
    "# \\[ A = \\begin{pmatrix} 4 & 1 \\\\ 2 & 3 \\end{pmatrix} \\]\n",
    "\n",
    "# The eigenvalues of \\(A\\) can be found by solving the characteristic equation \\(\\det(A - \\lambda I) = 0\\):\n",
    "# \\[ \\det \\begin{pmatrix} 4 - \\lambda & 1 \\\\ 2 & 3 - \\lambda \\end{pmatrix} = 0 \\]\n",
    "# \\[ (4 - \\lambda)(3 - \\lambda) - 2 = \\lambda^2 - 7\\lambda + 10 = 0 \\]\n",
    "# \\[ \\lambda = 5, \\lambda = 2 \\]\n",
    "\n",
    "# The corresponding eigenvectors can be found by solving \\((A - \\lambda I)v = 0\\):\n",
    "# For \\(\\lambda = 5\\):\n",
    "# \\[ \\begin{pmatrix} -1 & 1 \\\\ 2 & -2 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = 0 \\]\n",
    "# \\[ v = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\]\n",
    "\n",
    "# For \\(\\lambda = 2\\):\n",
    "# \\[ \\begin{pmatrix} 2 & 1 \\\\ 2 & 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = 0 \\]\n",
    "# \\[ v = \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix} \\]\n",
    "\n",
    "# ### Q2. What is eigen decomposition and what is its significance in linear algebra?\n",
    "\n",
    "# **Answer:**\n",
    "# Eigen decomposition is the process of decomposing a square matrix into its eigenvalues and eigenvectors. The significance of eigen decomposition in linear algebra includes:\n",
    "# - **Simplification:** It simplifies matrix operations, such as computing matrix powers and exponentials.\n",
    "# - **Diagonalization:** Diagonal matrices are easier to work with, and eigen decomposition allows us to diagonalize matrices.\n",
    "# - **Insight into Structure:** It provides insights into the properties and structure of the matrix, such as stability and resonance in systems.\n",
    "\n",
    "# ### Q3. What are the conditions that must be satisfied for a square matrix to be diagonalizable using the Eigen-Decomposition approach? Provide a brief proof to support your answer.\n",
    "\n",
    "# **Answer:**\n",
    "# A square matrix \\(A\\) is diagonalizable if and only if there are enough linearly independent eigenvectors to form a basis for the space. This requires that \\(A\\) has \\(n\\) linearly independent eigenvectors, where \\(n\\) is the size of the matrix.\n",
    "\n",
    "# **Proof:**\n",
    "# If \\(A\\) is diagonalizable, then:\n",
    "# \\[ A = V \\Lambda V^{-1} \\]\n",
    "# where \\(V\\) is the matrix of eigenvectors and \\(\\Lambda\\) is the diagonal matrix of eigenvalues.\n",
    "\n",
    "# For \\(V\\) to be invertible, its columns (eigenvectors) must be linearly independent. If \\(A\\) has \\(n\\) distinct eigenvalues, it guarantees \\(n\\) linearly independent eigenvectors, making \\(A\\) diagonalizable.\n",
    "\n",
    "# ### Q4. What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach? How is it related to the diagonalizability of a matrix? Explain with an example.\n",
    "\n",
    "# **Answer:**\n",
    "# The spectral theorem states that any symmetric (or Hermitian) matrix can be diagonalized by an orthogonal matrix. This means that for a symmetric matrix \\(A\\):\n",
    "# \\[ A = Q \\Lambda Q^T \\]\n",
    "# where \\(Q\\) is an orthogonal matrix whose columns are the eigenvectors of \\(A\\), and \\(\\Lambda\\) is a diagonal matrix of eigenvalues.\n",
    "\n",
    "# **Example:**\n",
    "# Consider a symmetric matrix \\(A\\):\n",
    "# \\[ A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} \\]\n",
    "\n",
    "# This matrix can be diagonalized using the spectral theorem:\n",
    "# \\[ A = Q \\Lambda Q^T \\]\n",
    "# where \\(Q\\) is orthogonal and \\(\\Lambda\\) contains the eigenvalues.\n",
    "\n",
    "# ### Q5. How do you find the eigenvalues of a matrix and what do they represent?\n",
    "\n",
    "# **Answer:**\n",
    "# To find the eigenvalues of a matrix \\(A\\), solve the characteristic equation:\n",
    "# \\[ \\det(A - \\lambda I) = 0 \\]\n",
    "\n",
    "# The eigenvalues represent the scaling factors by which the eigenvectors are stretched or compressed when the matrix is applied to them. They provide insights into the matrix's behavior and properties.\n",
    "\n",
    "# ### Q6. What are eigenvectors and how are they related to eigenvalues?\n",
    "\n",
    "# **Answer:**\n",
    "# Eigenvectors are non-zero vectors that change only in scale when a linear transformation is applied. They are related to eigenvalues through the equation:\n",
    "# \\[ A v = \\lambda v \\]\n",
    "# where \\(A\\) is the matrix, \\(v\\) is the eigenvector, and \\(\\lambda\\) is the corresponding eigenvalue. The eigenvector direction remains unchanged, and the eigenvalue determines the scaling factor.\n",
    "\n",
    "# ### Q7. Can you explain the geometric interpretation of eigenvectors and eigenvalues?\n",
    "\n",
    "# **Answer:**\n",
    "# Geometrically, eigenvectors represent directions in the vector space that remain invariant under the linear transformation represented by the matrix. Eigenvalues represent the scaling factors along these directions. For example, if \\(v\\) is an eigenvector of \\(A\\) with eigenvalue \\(\\lambda\\), applying \\(A\\) to \\(v\\) results in a vector that is \\(\\lambda\\) times \\(v\\).\n",
    "\n",
    "# ### Q8. What are some real-world applications of eigen decomposition?\n",
    "\n",
    "# **Answer:**\n",
    "# Real-world applications of eigen decomposition include:\n",
    "# - **Principal Component Analysis (PCA):** Used for dimensionality reduction and data compression.\n",
    "# - **Vibration Analysis:** Used to analyze natural frequencies and modes of mechanical systems.\n",
    "# - **Facial Recognition:** Eigenfaces technique relies on eigen decomposition for feature extraction.\n",
    "# - **Stability Analysis:** Used in control systems to analyze the stability of systems.\n",
    "\n",
    "# ### Q9. Can a matrix have more than one set of eigenvectors and eigenvalues?\n",
    "\n",
    "# **Answer:**\n",
    "# A matrix can have multiple eigenvectors corresponding to the same eigenvalue, forming an eigenspace. However, the set of eigenvalues is unique, and each eigenvalue can have one or more linearly independent eigenvectors.\n",
    "\n",
    "# ### Q10. In what ways is the Eigen-Decomposition approach useful in data analysis and machine learning? Discuss at least three specific applications or techniques that rely on Eigen-Decomposition.\n",
    "\n",
    "# **Answer:**\n",
    "# Eigen-Decomposition is useful in data analysis and machine learning in several ways:\n",
    "# - **Principal Component Analysis (PCA):** Used for reducing dimensionality and extracting features by projecting data onto principal components.\n",
    "# - **Spectral Clustering:** Uses eigenvalues and eigenvectors of similarity matrices to perform clustering in high-dimensional data.\n",
    "# - **Linear Discriminant Analysis (LDA):** Uses eigen decomposition for feature extraction and dimensionality reduction, enhancing class separability.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
